{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "This week we are going to use a new data set which contains 1070 purchases where the customer either purchased Citrus Hill or Minute Maid Orange Juice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals.six import StringIO \n",
    "from sklearn import tree\n",
    "import pydot\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Purchase</th>\n",
       "      <th>WeekofPurchase</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>PriceCH</th>\n",
       "      <th>PriceMM</th>\n",
       "      <th>DiscCH</th>\n",
       "      <th>DiscMM</th>\n",
       "      <th>SpecialCH</th>\n",
       "      <th>SpecialMM</th>\n",
       "      <th>LoyalCH</th>\n",
       "      <th>SalePriceMM</th>\n",
       "      <th>SalePriceCH</th>\n",
       "      <th>PriceDiff</th>\n",
       "      <th>Store7</th>\n",
       "      <th>PctDiscMM</th>\n",
       "      <th>PctDiscCH</th>\n",
       "      <th>ListPriceDiff</th>\n",
       "      <th>STORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091398</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>7</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956535</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Purchase  WeekofPurchase  StoreID  PriceCH  PriceMM  DiscCH  DiscMM  \\\n",
       "0         0             237        1     1.75     1.99    0.00     0.0   \n",
       "1         0             239        1     1.75     1.99    0.00     0.3   \n",
       "2         0             245        1     1.86     2.09    0.17     0.0   \n",
       "3         1             227        1     1.69     1.69    0.00     0.0   \n",
       "4         0             228        7     1.69     1.69    0.00     0.0   \n",
       "\n",
       "   SpecialCH  SpecialMM   LoyalCH  SalePriceMM  SalePriceCH  PriceDiff  \\\n",
       "0          0          0  0.500000         1.99         1.75       0.24   \n",
       "1          0          1  0.600000         1.69         1.75      -0.06   \n",
       "2          0          0  0.680000         2.09         1.69       0.40   \n",
       "3          0          0  0.400000         1.69         1.69       0.00   \n",
       "4          0          0  0.956535         1.69         1.69       0.00   \n",
       "\n",
       "   Store7  PctDiscMM  PctDiscCH  ListPriceDiff  STORE  \n",
       "0       0   0.000000   0.000000           0.24      1  \n",
       "1       0   0.150754   0.000000           0.24      1  \n",
       "2       0   0.000000   0.091398           0.23      1  \n",
       "3       0   0.000000   0.000000           0.00      1  \n",
       "4       1   0.000000   0.000000           0.00      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oj = pd.read_csv('OJ.csv')\n",
    "oj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oj.data = oj.iloc[:, 1:]\n",
    "oj.target = oj.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features and the target variable are already prepared for you. What you are going to do is:\n",
    "\n",
    "**1. Split**\n",
    "\n",
    "Split the data set into two parts: training set and test set(with *random_state=0*, and *test_size=1.0/2*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(oj.data, oj.target, random_state=0, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Support vector machine**\n",
    "\n",
    "(1) Fit a svm model on the training set, report the training error and test error.(Just use the **svm.SVC** with default setting.)\n",
    "    \n",
    "(2) Change the value of parameter $C$ from $10^{-3}$ to $10^3$, make a plot to watch how the training error and test error varies. You can choose the value of $C$ from the array `np.logspace(-3, 3, 300)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.773831775701\n",
      "Test Accuracy: 0.697196261682\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "print \"Training Accuracy:\", svm.score(x_train, y_train)\n",
    "print \"Test Accuracy:\", svm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEZCAYAAABWwhjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMVMQERGRmP1/b9RBhbs5Em4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111bb1410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = []\n",
    "test = []\n",
    "cVal = np.logspace(-3,3,300)\n",
    "\n",
    "for i in cVal:\n",
    "    svm = SVC(C=i)\n",
    "    svm.fit(x_train, y_train)\n",
    "    train.append(1 - svm.score(x_train, y_train))\n",
    "    test.append(1 - svm.score(x_test, y_test))\n",
    "    \n",
    "plt.plot(cVal, train)\n",
    "plt.plot(cVal, test)\n",
    "plt.legend(['Training Error', 'Test ERror'], loc=1)\n",
    "plt.title('Support Vector Machine Error')\n",
    "plt.xlabel('C Value')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Decision tree**\n",
    "\n",
    "(1) Fit a decision tree model on the training set with the default setting.\n",
    "    \n",
    "(2) Set the depth of the tree from 1 to 30. Look the varies of the training error and test error.\n",
    "    \n",
    "(3) Use the function **grid_search.GridSearchCV** to find the best parameters. What's the best parameters? What's the best score? What's the training error and test error of the best model. The possible combination of the parameters may be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_para_tree = {'criterion': ['gini', 'entropy'], 'max_depth': range(1, 31)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Plot the structure of the tree.\n",
    "    \n",
    "(5) What are the first 5 important features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.992523364486\n",
      "Test Accuracy: 0.770093457944\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train, y_train)\n",
    "print \"Training Accuracy:\", dtc.score(x_train, y_train)\n",
    "print \"Test Accuracy:\", dtc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>test_error</th>\n",
       "      <th>train_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.213084</td>\n",
       "      <td>0.216822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.239252</td>\n",
       "      <td>0.196262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.228037</td>\n",
       "      <td>0.168224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.207477</td>\n",
       "      <td>0.132710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.190654</td>\n",
       "      <td>0.123364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.196262</td>\n",
       "      <td>0.108411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.224299</td>\n",
       "      <td>0.078505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.224299</td>\n",
       "      <td>0.071028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.222430</td>\n",
       "      <td>0.052336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.218692</td>\n",
       "      <td>0.035514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.216822</td>\n",
       "      <td>0.024299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.231776</td>\n",
       "      <td>0.018692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.218692</td>\n",
       "      <td>0.011215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.226168</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.235514</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.216822</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.224299</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.220561</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.207477</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.239252</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.228037</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.244860</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.224299</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.220561</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.231776</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.213084</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.235514</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.222430</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.222430</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  test_error  train_error\n",
       "0           1    0.213084     0.216822\n",
       "1           2    0.239252     0.196262\n",
       "2           3    0.228037     0.168224\n",
       "3           4    0.207477     0.132710\n",
       "4           5    0.190654     0.123364\n",
       "5           6    0.196262     0.108411\n",
       "6           7    0.224299     0.078505\n",
       "7           8    0.224299     0.071028\n",
       "8           9    0.222430     0.052336\n",
       "9          10    0.218692     0.035514\n",
       "10         11    0.216822     0.024299\n",
       "11         12    0.231776     0.018692\n",
       "12         13    0.218692     0.011215\n",
       "13         14    0.226168     0.007477\n",
       "14         15    0.235514     0.007477\n",
       "15         16    0.241121     0.007477\n",
       "16         17    0.216822     0.007477\n",
       "17         18    0.224299     0.007477\n",
       "18         19    0.220561     0.007477\n",
       "19         20    0.207477     0.007477\n",
       "20         21    0.239252     0.007477\n",
       "21         22    0.228037     0.007477\n",
       "22         23    0.244860     0.007477\n",
       "23         24    0.224299     0.007477\n",
       "24         25    0.220561     0.007477\n",
       "25         26    0.231776     0.007477\n",
       "26         27    0.213084     0.007477\n",
       "27         28    0.235514     0.007477\n",
       "28         29    0.222430     0.007477\n",
       "29         30    0.222430     0.007477"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "test = []\n",
    "\n",
    "for d in range(1, 31):\n",
    "    dtc = DecisionTreeClassifier(max_depth=d)\n",
    "    dtc.fit(x_train, y_train)\n",
    "    train.append(1-dtc.score(x_train, y_train))\n",
    "    test.append(1-dtc.score(x_test, y_test))\n",
    "    \n",
    "errors = pd.DataFrame({'max_depth': range(1,31), 'train_error': train, 'test_error': test})\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'criterion': 'gini', 'max_depth': 4}\n",
      "Score: 0.805607476636\n",
      "Best Tree Training Score 0.867289719626\n",
      "Best Tree Test Score 0.792523364486\n"
     ]
    }
   ],
   "source": [
    "gridTree = GridSearchCV(DecisionTreeClassifier(), grid_para_tree)\n",
    "gridTree.fit(x_train, y_train)\n",
    "\n",
    "print \"Best Parameters:\"\n",
    "print gridTree.best_params_\n",
    "print \"Score:\", gridTree.best_score_\n",
    "\n",
    "treeBest = gridTree.best_estimator_\n",
    "print \"Best Tree Training Score\", treeBest.score(x_train, y_train)\n",
    "print \"Best Tree Test Score\", treeBest.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dot_data = StringIO() \n",
    "# tree.export_graphviz(treeBest, out_file=dot_data) \n",
    "# graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "# graph.write_png(\"bestTree.png\") \n",
    "\n",
    "# from IPython.display import Image\n",
    "# Image(filename='bestTree.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('WeekofPurchase', 0.016077940832034628), ('StoreID', 0.0), ('PriceCH', 0.0), ('PriceMM', 0.0), ('DiscCH', 0.0), ('DiscMM', 0.0), ('SpecialCH', 0.011291129668023547), ('SpecialMM', 0.0), ('LoyalCH', 0.7302123573772521), ('SalePriceMM', 0.0054886547065514284), ('SalePriceCH', 0.0), ('PriceDiff', 0.12488704135875678), ('Store7', 0.0), ('PctDiscMM', 0.0), ('PctDiscCH', 0.0), ('ListPriceDiff', 0.066720147947098601), ('STORE', 0.045322728110282838)]\n",
      "Top 5 Features: LoyalCH, PriceDiff, SalePriceCH, Special CH, WeekofPurchase\n"
     ]
    }
   ],
   "source": [
    "print zip(oj.data.columns, treeBest.feature_importances_)\n",
    "print \"Top 5 Features: LoyalCH, PriceDiff, SalePriceCH, Special CH, WeekofPurchase\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Random Forest.**\n",
    "\n",
    "(1) Fit a random forest on the training set. Report the training error and test error.\n",
    "    \n",
    "(2) Use the function **grid_search.GridSearchCV** to find the best parameters. What's the best parameters? What's the best score? What's the training error and test error of the best model. The possible combination of the parameters may be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_para_forest = {'criterion': ['gini', 'entropy'], 'max_depth': range(1, 31), \"n_estimators\": range(10, 110, 10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) What's the first 5 important features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.970093457944\n",
      "Test Accuracy: 0.764485981308\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "print \"Training Accuracy:\", rfc.score(x_train, y_train)\n",
    "print \"Test Accuracy:\", rfc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'n_estimators': 60, 'criterion': 'entropy', 'max_depth': 3}\n",
      "Score: 0.829906542056\n",
      "Best Tree Training Score 0.829906542056\n",
      "Best Tree Test Score 0.78691588785\n"
     ]
    }
   ],
   "source": [
    "grfc = GridSearchCV(RandomForestClassifier(), grid_para_forest)\n",
    "grfc.fit(x_train, y_train)\n",
    "\n",
    "print \"Best Parameters:\"\n",
    "print grfc.best_params_\n",
    "print \"Score:\", grfc.best_score_\n",
    "\n",
    "forestBest = grfc.best_estimator_\n",
    "print \"Best Tree Training Score\", forestBest.score(x_train, y_train)\n",
    "print \"Best Tree Test Score\", forestBest.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LoyalCH</td>\n",
       "      <td>0.430642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StoreID</td>\n",
       "      <td>0.077224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ListPriceDiff</td>\n",
       "      <td>0.076347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SalePriceMM</td>\n",
       "      <td>0.063970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>STORE</td>\n",
       "      <td>0.061824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features  importance\n",
       "8         LoyalCH    0.430642\n",
       "1         StoreID    0.077224\n",
       "15  ListPriceDiff    0.076347\n",
       "9     SalePriceMM    0.063970\n",
       "16          STORE    0.061824"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({'features':x_train.columns, 'importance': forestBest.feature_importances_}).sort_values(by='importance', ascending=False)\n",
    "feature_importance[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
